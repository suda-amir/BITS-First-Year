{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for binary classification\n",
    "\n",
    "<b>Logistic model</b>  is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick.\n",
    "\n",
    "A <b>binary logistic model</b> has a dependent variable with two possible values, such as pass/fail which is represented by labels 1/0. \n",
    "\n",
    "<div align=\"right\">   Reference: Wikipedia </div> \n",
    "\n",
    "\n",
    "In <b>logistic classification</b>, the classification is based on the hypothesis $ h_\\theta(x) $:\n",
    "\n",
    "If $ h_\\theta(x) \\geq 0.5 $ predict $ y = 1 $.\n",
    "\n",
    "If $ h_\\theta(x) < 0.5 $ predict $ y = 0 $. \n",
    "\n",
    "In other words,  $ 0 \\leq h_\\theta(x) \\leq 1 $.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![title](images/LogisticRegression.png)\n",
    "\n",
    "<div align=\"right\">   Reference: techdifferences.com </div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Know and prepare the dataset\n",
    "\n",
    "Iris dataset consists of 150 observations. \n",
    "\n",
    "The features or attributed (columns) are Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "The observations (rows) belong to 3 different types of iris species - Setosa, Versicolour, and Virginica. Each class has 50 observations.\n",
    "\n",
    "The iris dataset can be downloded from Kaggle: https://www.kaggle.com/uciml/iris as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset from the library\n",
    "\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only the fourth feature or column - petal width\n",
    "\n",
    "X = iris[\"data\"][:,3:]  \n",
    "\n",
    "# consider only the class 2.\n",
    "# similar to one-vs-all case.\n",
    "\n",
    "y = (iris[\"target\"]==2).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 1)\n",
      "(45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, stratify=y, test_size= 0.3)\n",
    "\n",
    "# testing size = 30 %\n",
    "# rest 70 % is used for training\n",
    "# stratify parameter ensures that observations from each class is are given equal weightage\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and train the machine learning modelÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "\n",
    "logistic_model = LogisticRegression(solver='lbfgs') # default classfier\n",
    "\n",
    "logistic_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict values for the test data\n",
    "y_prob  = logistic_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.77777777777777\n"
     ]
    }
   ],
   "source": [
    "# compute the accuracy\n",
    "\n",
    "acc = accuracy_score(y_test, y_prob)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[29  1]\n",
      " [ 0 15]]\n"
     ]
    }
   ],
   "source": [
    "# build the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_prob) \n",
    "print('Confusion Matrix :')\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Accuracy = \\frac{(TP+TN)}{(P+N)} $$\n",
    "\n",
    "$$  Precision = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "$$ Recall = Sensitivity = \\frac{TP}{P} $$ \n",
    "\n",
    "$$ F1 Score = 2 * \\frac{(precision * recall)}{(precision + recall)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        30\n",
      "           1       0.94      1.00      0.97        15\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report - precision, recall\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_test, y_prob))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
